<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Run Our Notebook in Google Colab</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 700px;
            margin: 40px auto;
            padding: 20px;
            line-height: 1.6;
        }
        .button {
            display: inline-block;
            margin-top: 20px;
        }
        .button img {
            height: 40px;
        }
    </style>
</head>
<body>

    <h1>Cross-Validation with YOLO</h1>   


    <footer style="margin-top: 40px; font-size: 0.9em; color: #555;">
    <p><strong>Authors:</strong> Dr. Chloe Game (<a href="https://github.com/CGame1">CGame1</a>), University of Bergen (UiB)&nbsp;| Dr. Nils Piechaud (<a href="https://github.com/Npiechaud">Npiechaud</a>), Institute of Marine Research (IMR)&nbsp; </p>
</footer>



   <hr>

    <p>Welcome! This page provides access to a Jupyter notebook that demonstrates how to implement cross-validation with YOLO for image classification in Python. üì∑üåäüêôü§ñ
</p> 
    <p>The notebook is designed to be beginner-friendly, with the option to run it entirely online using <a href="https://colab.research.google.com/github/CGame1/img_classification_guide/blob/main/CrossVal_with_Yolo_colab.ipynb">Google Colab</a> ‚Äî no installation or GPU required.
If you're more comfortable with Python and Jupyter, you can also download or clone the notebook from <a href="https://github.com/CGame1/img_classification_guide">Github</a> and run it locally. No data is required as the code also downloads an open-source  <a href="https://doi.pangaea.de/10.1594/PANGAEA.949920."> dataset</a>, see <a href="https://www.sciencedirect.com/science/article/pii/S0967063722002333#da0010">Meyer et al., 2023</a> for details. </p>


   <p>This resource is a supplement to our paper: <a href="">ADD Title</a>. </p>
</p> 
 


<figure style="text-align: center; margin: 30px 0;">
    <img src="https://github.com/CGame1/Mutli-modal-learning-poster/blob/main/workflow.png?raw=true" 
         alt="Classification workflow" 
         style="max-width: 100%; height: auto; border: 1px solid #ccc; border-radius: 8px;">
    <figcaption style="margin-top: 10px; font-size: 0.9em; color: #555;">
       Figure 1: Simplified and idealized diagram of an image classification scenario. Each box represents a key task and corresponds to a section of the paper to aid comprehension.  While presented largely linearly for clarity, real-world ML workflows are often iterative and non-linear and the need to revisit specific sections may vary depending on the scenario.
    </figcaption>
</figure>

<hr>
<h2>üìö How to Cite This Work</h2>

<p>If you find this code useful, please consider citing us :</p>

<blockquote style="background-color: #f9f9f9; border-left: 4px solid #ccc; padding: 10px; font-style: italic;">
    Your Name, Another Author, and Third Author. <strong>‚ÄúTitle of the Paper.‚Äù</strong> Journal Name, vol. XX, no. X, Year, pp. XX‚ÄìXX. DOI: <a href="https://doi.org/your-doi">https://doi.org/your-doi</a>.
</blockquote>

<p>Or use the following BibTeX entry:</p>



<pre style="background-color: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto;">
@article{your2025paper,
  title     = {Title of the Paper},
  author    = {Your Name and Another Author and Third Author},
  journal   = {Journal Name},
  volume    = {XX},
  number    = {X},
  pages     = {XX--XX},
  year      = {2025},
  doi       = {10.xxxx/your-doi}
}
</pre>

